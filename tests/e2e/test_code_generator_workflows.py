"""End-to-end tests for Python code generator workflows.

These tests validate the complete code generation pipeline including:
1. Configuration loading (basic vs claude_code generators)
2. Example script reading and guidance following
3. Code generation with specific instructions
4. Code execution and validation

Tests use LLM judges to evaluate both code quality and instruction following.
"""

import json

import pytest

# Check if Claude SDK is available using the framework's detection
try:
    from osprey.services.python_executor.generation import CLAUDE_SDK_AVAILABLE
except ImportError:
    CLAUDE_SDK_AVAILABLE = False


# Test-specific example script with non-normal instructions
EXAMPLE_PLOTTING_SCRIPT = '''"""Example plotting script with special header requirement.

This script demonstrates the REQUIRED header format for all generated plots.
ALL plots must include this exact header comment.
"""

import matplotlib.pyplot as plt
import numpy as np

# âš ï¸ REQUIRED: All generated scripts MUST start with this exact header comment:
# "Generated by Osprey Framework - Data Visualization Module"
# This is our facility's standard plot header.

# Example: Simple line plot
x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(10, 6))
plt.plot(x, y)
plt.xlabel('X values')
plt.ylabel('Y values')
plt.title('Example Plot')
plt.grid(True)
plt.savefig('example_plot.png', dpi=150, bbox_inches='tight')
plt.close()

print("Plot saved successfully")
results = {'plot_file': 'example_plot.png', 'status': 'success'}
'''

EXAMPLE_README = '''# Plotting Examples

## Important Conventions

**CRITICAL REQUIREMENT**: All plotting scripts generated for this facility MUST begin with the following header comment:

```python
# Generated by Osprey Framework - Data Visualization Module
```

This header is required by our facility's documentation standards and helps track generated code.

## Example Scripts

See `example_plot.py` for a complete example that includes:
- The required header comment
- Proper imports
- Figure configuration
- Saving with correct DPI (150)
- Clean figure closure
- Results dictionary

## Best Practices

1. Always start scripts with the required header comment
2. Use `figsize=(10, 6)` for standard plots
3. Save with `dpi=150` and `bbox_inches='tight'`
4. Close figures after saving to free memory
5. Store output paths in `results` dictionary
'''


@pytest.mark.e2e
@pytest.mark.slow
@pytest.mark.requires_cborg
@pytest.mark.asyncio
async def test_basic_generator_simple_code_generation(e2e_project_factory):
    """Test basic generator creates simple, functional Python code.

    This validates:
    1. Basic generator configuration loads correctly
    2. Simple prompt-based code generation works
    3. Generated code executes successfully
    4. Results are returned properly

    Note: Basic generator does NOT read example scripts - it's a simple
    prompt-to-code generator. For codebase reading, see Claude Code tests.
    """
    # Step 1: Create project with basic generator (default for control_assistant)
    project = await e2e_project_factory(
        name="test-basic-generator",
        template="control_assistant",
        registry_style="extend"
    )

    # Step 2: Initialize framework
    await project.initialize()

    # Step 3: Request a very simple calculation and plot
    result = await project.query(
        "Calculate the sum of numbers 1 through 10 and create a simple bar chart showing these numbers. "
        "Save the plot as a PNG file."
    )

    # Step 4: Verify workflow completed without errors
    assert result.error is None, f"Workflow error: {result.error}"

    # Step 5: Verify Python capability was executed
    trace_lower = result.execution_trace.lower()
    assert "python" in trace_lower, (
        "Python capability not executed - check execution trace:\n"
        f"{result.execution_trace[:500]}"
    )

    # Step 6: Verify plot artifact was created
    assert len(result.artifacts) > 0, (
        f"Expected at least one artifact (plot), got {len(result.artifacts)}"
    )

    # Step 7: Verify at least one PNG file was created
    png_files = [a for a in result.artifacts if str(a).lower().endswith('.png')]
    assert len(png_files) > 0, (
        f"Expected PNG file in artifacts, got: {result.artifacts}"
    )

    # Step 8: Verify response indicates success
    response_lower = result.response.lower()
    assert any(word in response_lower for word in ['success', 'created', 'saved', 'completed']), (
        f"Response does not indicate successful completion:\n{result.response[:300]}"
    )

    print(f"âœ… Basic generator test passed - created {len(result.artifacts)} artifact(s)")


@pytest.mark.e2e
@pytest.mark.slow
@pytest.mark.requires_cborg
@pytest.mark.skipif(
    not CLAUDE_SDK_AVAILABLE,
    reason="Claude Agent SDK not installed"
)
@pytest.mark.asyncio
async def test_claude_code_generator_with_codebase_guidance(e2e_project_factory, tmp_path):
    """Test Claude Code generator reads example scripts and follows guidance.

    This validates:
    1. Claude Code generator configuration loads correctly
    2. claude_generator_config.yml is parsed and used
    3. Fast profile (single generate phase) executes
    4. Example scripts are copied to isolated directory and read
    5. README guidance is followed (header requirement)
    6. Generated code executes successfully
    7. Specific instruction appears in generated code
    """
    # Step 1: Create project with control_assistant template
    project = await e2e_project_factory(
        name="test-claude-code",
        template="control_assistant",
        registry_style="extend"
    )

    # Step 2: Modify config.yml to use claude_code generator
    config_path = project.project_dir / "config.yml"
    config_content = config_path.read_text()

    # Replace basic generator with claude_code
    config_content = config_content.replace(
        'code_generator: "basic"',
        'code_generator: "claude_code"'
    )
    config_path.write_text(config_content)

    # Step 3: Generate claude_generator_config.yml
    from osprey.cli.templates import TemplateManager
    template_manager = TemplateManager()

    ctx = {
        "default_provider": "cborg",
        "default_model": "anthropic/claude-haiku"
    }

    template_manager.render_template(
        "apps/control_assistant/claude_generator_config.yml.j2",
        ctx,
        project.project_dir / "claude_generator_config.yml"
    )

    # Step 4: Set up example scripts with specific guidance
    example_scripts_dir = project.project_dir / "_agent_data" / "example_scripts" / "plotting"
    example_scripts_dir.mkdir(parents=True, exist_ok=True)

    # Write example script with non-normal instruction
    (example_scripts_dir / "example_plot.py").write_text(EXAMPLE_PLOTTING_SCRIPT)

    # Write README with the specific requirement
    (example_scripts_dir / "README.md").write_text(EXAMPLE_README)

    # Step 5: Initialize framework (will load claude_code generator)
    await project.initialize()

    # Step 6: Request a plot that should trigger codebase reading
    result = await project.query(
        "Create a cosine wave plot from 0 to 2Ï€ with 100 points. "
        "Save it as a PNG file with a clear title."
    )

    # Step 7: Verify workflow completed without errors
    assert result.error is None, f"Workflow error: {result.error}"

    # Step 8: Verify Python execution happened
    trace_lower = result.execution_trace.lower()
    assert "python" in trace_lower or "code" in trace_lower, (
        "Python code generation/execution not performed - check execution trace:\n"
        f"{result.execution_trace[:500]}"
    )

    # Step 9: Critical check - Verify the specific header instruction was followed
    # Find the actual generated code (Python script or Jupyter notebook)

    executed_scripts_dir = project.project_dir / "_agent_data" / "executed_scripts"

    # Look for the generated Python scripts
    python_files = list(executed_scripts_dir.glob("**/*.py"))
    # Look for Jupyter notebooks
    notebook_files = list(executed_scripts_dir.glob("**/*.ipynb"))

    assert len(python_files) > 0 or len(notebook_files) > 0, (
        f"No generated code files found!\n"
        f"Searched in: {executed_scripts_dir}\n"
        f"Python files: {len(python_files)}, Notebooks: {len(notebook_files)}"
    )

    # Get the most recent code file (prefer .py files)
    code_files = python_files if python_files else notebook_files
    latest_code_file = max(code_files, key=lambda p: p.stat().st_mtime)

    # Read the generated code
    generated_code = latest_code_file.read_text()

    # Step 10: Verify the generated code includes the required header
    # This is the KEY validation - it proves Claude read AND followed the README guidance
    required_header = "Generated by Osprey Framework - Data Visualization Module"
    has_header = required_header in generated_code

    # Step 11: Optional - Check if Claude read the example file (from conversation log)
    conversation_files = list(executed_scripts_dir.glob("**/prompts/conversation_full.json"))
    read_example = False
    if conversation_files:
        latest_conversation = max(conversation_files, key=lambda p: p.stat().st_mtime)
        with open(latest_conversation) as f:
            conversation_data = json.load(f)
        conversation_str = json.dumps(conversation_data)
        read_example = "example_plot.py" in conversation_str

    # Debug output
    print("\nğŸ” Codebase Guidance Validation:")
    print(f"   ğŸ“„ Generated code file: {latest_code_file.name}")
    print(f"   ğŸ“– Claude read example_plot.py: {read_example}")
    print(f"   âœ¨ Generated code has required header: {has_header}")

    assert has_header, (
        f"Generated code missing required header comment!\n"
        f"File: {latest_code_file}\n"
        f"Expected header: '{required_header}'\n"
        f"This proves Claude did NOT follow the README guidance from the example scripts.\n"
        f"First 500 chars of generated code:\n{generated_code[:500]}"
    )

    # Step 12: Verify plot artifacts were created
    assert len(result.artifacts) > 0, (
        f"Expected plot artifacts, got {len(result.artifacts)}"
    )

    # Step 13: Verify PNG file was created
    png_files = [a for a in result.artifacts if str(a).lower().endswith('.png')]
    assert len(png_files) > 0, (
        f"Expected PNG file in artifacts, got: {result.artifacts}"
    )

    print(f"âœ… Claude Code codebase guidance test passed - header found, {len(png_files)} PNG(s) created")


@pytest.mark.e2e
@pytest.mark.slow
@pytest.mark.requires_cborg
@pytest.mark.skipif(
    not CLAUDE_SDK_AVAILABLE,
    reason="Claude Agent SDK not installed"
)
@pytest.mark.asyncio
async def test_claude_code_robust_profile_workflow(e2e_project_factory):
    """Test Claude Code generator robust profile (multi-phase workflow).

    This validates that the robust profile (scan â†’ plan â†’ implement) works
    correctly with all phases executing in sequence.
    """
    # Step 1: Create project
    project = await e2e_project_factory(
        name="test-claude-robust",
        template="control_assistant",
        registry_style="extend"
    )

    # Step 2: Configure for claude_code with robust profile
    config_path = project.project_dir / "config.yml"
    config_content = config_path.read_text()

    # Switch to claude_code
    config_content = config_content.replace(
        'code_generator: "basic"',
        'code_generator: "claude_code"'
    )
    config_path.write_text(config_content)

    # Step 3: Generate claude config with robust profile
    from osprey.cli.templates import TemplateManager
    template_manager = TemplateManager()

    ctx = {
        "default_provider": "cborg",
        "default_model": "anthropic/claude-haiku"
    }

    claude_config_path = project.project_dir / "claude_generator_config.yml"
    template_manager.render_template(
        "apps/control_assistant/claude_generator_config.yml.j2",
        ctx,
        claude_config_path
    )

    # Modify to use robust profile by updating config.yml
    config_content = config_path.read_text()
    config_content = config_content.replace(
        'profile: "fast"',
        'profile: "robust"'
    )
    config_path.write_text(config_content)

    # Step 4: Initialize
    await project.initialize()

    # Step 5: Execute a query that benefits from planning
    result = await project.query(
        "Create a multi-panel figure with 4 subplots showing: "
        "1) sine wave, 2) cosine wave, 3) their sum, 4) their product. "
        "Each subplot should be clearly labeled."
    )

    # Step 6: Verify workflow completed without errors
    assert result.error is None, f"Workflow error: {result.error}"

    # Step 7: Verify Python execution happened
    trace_lower = result.execution_trace.lower()
    assert "python" in trace_lower or "code" in trace_lower, (
        "Python code generation/execution not performed - check execution trace:\n"
        f"{result.execution_trace[:500]}"
    )

    # Step 8: Verify plot artifacts were created
    assert len(result.artifacts) > 0, (
        f"Expected plot artifacts, got {len(result.artifacts)}"
    )

    # Step 9: Verify PNG file was created
    png_files = [a for a in result.artifacts if str(a).lower().endswith('.png')]
    assert len(png_files) > 0, (
        f"Expected PNG file in artifacts, got: {result.artifacts}"
    )

    # Step 10: Verify response indicates success
    response_lower = result.response.lower()
    assert any(word in response_lower for word in ['success', 'created', 'saved', 'completed', 'subplot']), (
        f"Response does not indicate successful completion:\n{result.response[:300]}"
    )

    # Step 11: Optional - check for multi-phase indicators (scan/plan/implement)
    # This is informational and not critical to the test passing
    prompts_dir = project.project_dir / "_agent_data" / "executed_scripts"
    conversation_files = list(prompts_dir.glob("**/prompts/conversation_full.json"))

    if conversation_files:
        latest_conversation = max(conversation_files, key=lambda p: p.stat().st_mtime)
        with open(latest_conversation) as f:
            conversation_data = json.load(f)
        conversation_str = json.dumps(conversation_data).lower()

        # Look for phase indicators
        has_scan = "scan" in conversation_str
        has_plan = "plan" in conversation_str

        print("\nğŸ” Robust Profile Validation:")
        print(f"   ğŸ“ Conversation file: {latest_conversation.name}")
        print(f"   ğŸ” Scan phase detected: {has_scan}")
        print(f"   ğŸ“‹ Plan phase detected: {has_plan}")

    print(f"âœ… Claude Code robust profile test passed - {len(png_files)} PNG(s) created")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])

